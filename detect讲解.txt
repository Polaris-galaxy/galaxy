1. 参数解析（Argument Parsing）
使用 argparse 定义命令行参数，控制检测流程的核心参数。

python
def parse_opt():
    parser = argparse.ArgumentParser()
    # 模型参数
    parser.add_argument('--weights', nargs='+', type=str, default=ROOT / 'yolov5s.pt', help='模型路径')
    parser.add_argument('--source', type=str, default=ROOT / 'data/images', help='输入源路径')
    # 推理参数
    parser.add_argument('--img-size', '--imgsz', type=int, default=640, help='推理尺寸（像素）')
    parser.add_argument('--conf-thres', type=float, default=0.25, help='置信度阈值')
    parser.add_argument('--iou-thres', type=float, default=0.45, help='NMS的IoU阈值')
    # 输出参数
    parser.add_argument('--save-txt', action='store_true', help='保存检测结果到TXT文件')
    parser.add_argument('--save-conf', action='store_true', help='在TXT中保存置信度')
    parser.add_argument('--classes', nargs='+', type=int, help='指定检测类别（如 --classes 0 2 3）')
    # 设备参数
    parser.add_argument('--device', default='', help='使用设备（cuda:0 或 cpu）')
    parser.add_argument('--view-img', action='store_true', help='实时显示结果')
    opt = parser.parse_args()
    return opt
关键参数：

--weights: 支持多个模型路径（如集成模型）。

--source: 输入源可以是图像、视频、目录、URL或摄像头（0 表示摄像头）。

--img-size: 输入图像会被缩放到此尺寸（保持长宽比）。

2. 模型加载（Model Loading）
加载预训练模型并初始化推理配置。

python
from models.common import DetectMultiBackend
from utils.torch_utils import select_device

def load_model(weights, device):
    # 选择设备（GPU/CPU）
    device = select_device(device)
    # 加载模型（支持PyTorch、ONNX、TensorRT等格式）
    model = DetectMultiBackend(weights, device=device)
    # 设置模型为推理模式
    model.eval()
    # 半精度推理（FP16）
    if half:
        model.half()
    return model
关键点：

DetectMultiBackend 类支持多种后端（PyTorch、ONNX、TensorRT等）。

model.eval() 禁用Dropout和BatchNorm层，固定模型参数。

3. 数据加载与预处理（Data Loading & Preprocessing）
处理不同输入源（图像/视频/摄像头），并进行标准化处理。

python
from utils.dataloaders import LoadImages

dataset = LoadImages(source, img_size=imgsz, stride=stride)

for path, im, im0s, vid_cap, s in dataset:
    # im: 预处理后的图像（BCHW格式，归一化到0-1）
    # im0s: 原始图像（未处理，用于可视化）
    pass
预处理流程：

Letterbox缩放：保持原始宽高比，填充至img_size。

归一化：像素值从 0-255 归一化到 0.0-1.0。

通道转换：从 HWC 转换为 BCHW 格式（PyTorch输入格式）。

数据类型转换：转为 torch.float16（半精度）或 torch.float32。

4. 推理（Inference）
模型前向传播，输出检测结果。

python
import torch

# 图像张量转换（numpy转torch）
im = torch.from_numpy(im).to(device)
im = im.half() if half else im.float()  # uint8→float16/32
im /= 255  # 归一化到 [0.0, 1.0]
if len(im.shape) == 3:
    im = im[None]  # 添加batch维度（BCHW → 1CHW）

# 前向推理（无梯度计算）
with torch.no_grad():
    pred = model(im, augment=False, visualize=False)
输出格式：

pred 是一个列表，每个元素对应一个图像的检测结果。

每个检测框的格式为 [x1, y1, x2, y2, confidence, class_id]。

5. 后处理（Post-Processing）
应用非极大值抑制（NMS）过滤冗余检测框。

python
from utils.general import non_max_suppression

# 应用NMS
pred = non_max_suppression(
    prediction=pred, 
    conf_thres=conf_thres, 
    iou_thres=iou_thres, 
    classes=classes, 
    agnostic=False
)
NMS过程：

按类别分组，逐类别处理。

根据置信度排序，保留最高置信度的框。

计算IoU，移除重叠超过阈值的框。

6. 结果可视化与保存
将检测框绘制到原始图像，并保存结果。

python
from utils.plots import Annotator, colors

for det in pred:  # 遍历每张图像的检测结果
    annotator = Annotator(im0, line_width=3, example=str(names))
    if len(det):
        # 将检测框坐标从缩放后的尺寸映射回原始尺寸
        det[:, :4] = scale_coords(im.shape[2:], det[:, :4], im0.shape).round()
        # 绘制检测框
        for *xyxy, conf, cls in reversed(det):
            c = int(cls)
            label = f'{names[c]} {conf:.2f}'
            annotator.box_label(xyxy, label, color=colors(c, True))
    # 显示或保存结果
    cv2.imshow('result', im0)
    cv2.imwrite(save_path, im0)
关键函数：

scale_coords(): 将检测框坐标从预处理尺寸映射回原始图像尺寸。

Annotator.box_label(): 绘制边界框和标签。

7. 保存检测结果
保存检测框的坐标、类别和置信度到文本文件。

python
def save_txt(txt_path, det, img_shape):
    # 格式：class_id x_center y_center width height (归一化坐标)
    gn = torch.tensor(img_shape)[[1, 0, 1, 0]]  # 归一化系数
    for *xyxy, conf, cls in det:
        xywh = (xyxy2xywh(torch.tensor(xyxy).view(1, 4)) / gn).view(-1).tolist()
        line = (cls, *xywh, conf) if save_conf else (cls, *xywh)
        with open(txt_path, 'a') as f:
            f.write(('%g ' * len(line)).rstrip() % line + '\n')
保存格式示例：

0 0.5 0.6 0.3 0.4  # 类别0，中心点(0.5,0.6)，宽0.3，高0.4
8. 核心工具函数
Letterbox缩放
python
def letterbox(im, new_shape=(640, 640), color=(114, 114, 114)):
    # 保持宽高比缩放图像，填充到目标尺寸
    shape = im.shape[:2]  # 原始尺寸 [height, width]
    # 计算缩放比例
    r = min(new_shape[0] / shape[0], new_shape[1] / shape[1])
    # 计算填充
    new_unpad = int(round(shape[1] * r)), int(round(shape[0] * r))
    dw, dh = new_shape[1] - new_unpad[0], new_shape[0] - new_unpad[1]
    # 分割填充（上下左右均匀填充）
    dw /= 2
    dh /= 2
    # 执行缩放和填充
    if shape[::-1] != new_unpad:
        im = cv2.resize(im, new_unpad, interpolation=cv2.INTER_LINEAR)
    top, bottom = int(round(dh - 0.1)), int(round(dh + 0.1))
    left, right = int(round(dw - 0.1)), int(round(dw + 0.1))
    im = cv2.copyMakeBorder(im, top, bottom, left, right, cv2.BORDER_CONSTANT, value=color)
    return im
9. 完整流程总结
参数解析：读取命令行参数，设置推理配置。

模型初始化：加载权重，设置设备（GPU/CPU），切换推理模式。

数据加载：根据输入源类型读取数据，逐帧处理。

预处理：Letterbox缩放 → 归一化 → 转换为PyTorch张量。

推理：模型前向传播，输出原始检测框。

后处理：置信度过滤 → NMS → 坐标映射回原始图像。

可视化与保存：绘制检测框，显示或保存结果。

10. 关键优化技巧
半精度推理：通过 --half 启用FP16，显存占用减少约50%，速度提升20-30%。

批处理推理：修改代码支持批量输入（需调整数据加载部分）。

TensorRT加速：将模型导出为 .engine 格式，显著提升推理速度。

自定义输出：修改 Annotator 类或 save_txt 函数，添加业务逻辑。